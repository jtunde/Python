{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NSLKDDAllClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jtunde/Python/blob/main/NSLKDDAllClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8D1iBYAxCh20"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def proc_categ(values):\n",
        "    categ = values.value_counts()\n",
        "    count = float(len(values))\n",
        "    res = \"\"\n",
        "    for idx in categ.index:\n",
        "        res += idx\n",
        "        res += \" \" + str(categ[idx]) + \" \" + str(100*round(categ[idx] / count,4)) + \"%, \"\n",
        "    return res\n",
        "\n",
        "def example_plot(normal_values, attack_values):\n",
        "    # Plot a selection of features\n",
        "    fig, axs = plt.subplots(3, 2)\n",
        "\n",
        "    # The first column will plot the normal, the second the attack\n",
        "    axs[0, 0].plot(normal_values[37])#dst_host_serror_rate\n",
        "    axs[0, 0].set_title('Normal: % dest. connections with SYN errors')\n",
        "    axs[0, 1].plot(attack_values[37])#dst_host_serror_rate\n",
        "    axs[0, 1].set_title('Attack: % dest. connections with SYN errors')\n",
        "\n",
        "    axs[1, 0].plot(normal_values[24])#serror_rate\n",
        "    axs[1, 0].set_title('Normal: % connections with SYN errors')\n",
        "    axs[1, 1].plot(attack_values[24])#serror_rate\n",
        "    axs[1, 1].set_title('Attack: % connections with SYN errors')\n",
        "\n",
        "    axs[2, 0].plot(normal_values[4])#src_bytes\n",
        "    axs[2, 0].set_title('Normal: src bytes')\n",
        "    axs[2, 1].plot(attack_values[4])#src_bytes\n",
        "    axs[2, 1].set_title('Attack: src bytes')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "nls_columns = [\n",
        "    'duration',\n",
        "    'protocol_type',\n",
        "    'service',\n",
        "    'flag',\n",
        "    'src_bytes',\n",
        "    'dst_bytes',\n",
        "    'land',\n",
        "    'wrong_fragment',\n",
        "    'urgent',\n",
        "    'hot',\n",
        "    'num_failed_logins',\n",
        "    'logged_in',\n",
        "    'num_compromised',\n",
        "    'root_shell',\n",
        "    'su_attempted',\n",
        "    'num_root',\n",
        "    'num_file_creations',\n",
        "    'num_shells',\n",
        "    'num_access_files',\n",
        "    'num_outbound_cmds',\n",
        "    'is_host_login',\n",
        "    'is_guest_login',\n",
        "    'count',\n",
        "    'srv_count',\n",
        "    'serror_rate',\n",
        "    'srv_serror_rate',\n",
        "    'rerror_rate',\n",
        "    'srv_rerror_rate',\n",
        "    'same_srv_rate',\n",
        "    'diff_srv_rate',\n",
        "    'srv_diff_host_rate',\n",
        "    'dst_host_count',\n",
        "    'dst_host_srv_count',\n",
        "    'dst_host_same_srv_rate',\n",
        "    'dst_host_diff_srv_rate',\n",
        "    'dst_host_same_src_port_rate',\n",
        "    'dst_host_srv_diff_host_rate',\n",
        "    'dst_host_serror_rate',\n",
        "    'dst_host_srv_serror_rate',\n",
        "    'dst_host_rerror_rate',\n",
        "    'dst_host_srv_rerror_rate',\n",
        "    'class']\n",
        "\n",
        "CLASSIFIER_COLUMN = 41\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('sample_data/KDDTrain+_20Percent.txt', header=None)"
      ],
      "metadata": {
        "id": "LT1m3SrrDm0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[0:10])\n",
        "print(\"Attack type statistics:\" + proc_categ(df[41]))\n",
        "print(\"Protocol statistics:\" + proc_categ(df[1]))"
      ],
      "metadata": {
        "id": "VmUUYrJiD28C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_val = df.loc[df[41] == 'normal']\n",
        "syn_val = df.loc[df[41] == 'neptune']\n",
        "print(\"NORMAL data count: \" + str(len(normal_val)))\n",
        "print(\"SYN data count: \" + str(len(syn_val)))\n",
        "\n",
        "example_plot(normal_val, syn_val)"
      ],
      "metadata": {
        "id": "Oo-gaHClFBUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_labels(df):\n",
        "    categ = df[CLASSIFIER_COLUMN].value_counts()\n",
        "    labels = {}\n",
        "    ctr = 0\n",
        "    for idx in categ.index:\n",
        "        labels[idx] = ctr\n",
        "        ctr += 1\n",
        "\n",
        "        df.loc[(df[CLASSIFIER_COLUMN] == idx), CLASSIFIER_COLUMN] = ctr\n",
        "\n",
        "    return df\n",
        "\n",
        "# Place integer values in column 41 (the class column)\n",
        "dflab = prepare_labels(df)\n",
        "dflab[CLASSIFIER_COLUMN] = pd.to_numeric(dflab[CLASSIFIER_COLUMN]) # Make it numeric, so that it is not eliminated by the preprocessing!!!\n",
        "print(dflab)"
      ],
      "metadata": {
        "id": "LFObhAdlGe8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preproc_data(df):\n",
        "    # We delete columns with 0\n",
        "    df = df.loc[:, (df != 0).any(axis=0)]\n",
        "\n",
        "    # We delete columns with non-numeric values\n",
        "    non_numerical = []\n",
        "    for col in df:\n",
        "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
        "            non_numerical.append(col)\n",
        "    df = df.drop(columns=non_numerical)\n",
        "\n",
        "    # Normalize columns - min-max normalization ([0,1] interval)\n",
        "    for col in df:\n",
        "        if col == CLASSIFIER_COLUMN: # Skip the classifier column\n",
        "            continue\n",
        "        df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
        "\n",
        "    return df\n",
        "\n",
        "# Remove last column - it contains traffic type, we do not care about that\n",
        "dflab_proc = dflab.iloc[:,:(len(dflab.columns)-1)]\n",
        "\n",
        "# Remove zeros and non-numeric columns\n",
        "dflab_proc = preproc_data(dflab_proc)\n",
        "print(dflab_proc)"
      ],
      "metadata": {
        "id": "EXCpQnnGHSlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare dataset for training and for testing\n",
        "df_train = dflab_proc.iloc[0:(int(len(dflab_proc.index)/2)),:]\n",
        "df_pred = dflab_proc.iloc[(int(len(dflab_proc.index)/2)):,:]"
      ],
      "metadata": {
        "id": "5gPwpVoxIPtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "def rand_forest_fit(dfin):\n",
        "    # Perform a random forest-based classification\n",
        "    rf = RandomForestClassifier(n_estimators = 200, random_state = 42, max_depth = 30, min_samples_leaf = 4, min_samples_split = 5, oob_score = True)\n",
        "\n",
        "    # Prepare the data\n",
        "    data_arr = dfin.to_numpy()\n",
        "    nb_cols = numpy.shape(data_arr)[1]\n",
        "\n",
        "    train_data = data_arr[:,0:(nb_cols-2)]\n",
        "    label_data = data_arr[:,nb_cols-1]\n",
        "\n",
        "    print(label_data)\n",
        "\n",
        "    # Now train the model\n",
        "    rf.fit(train_data, label_data)\n",
        "\n",
        "    # Show importance\n",
        "    features = dfin.columns.to_numpy()\n",
        "    features = features[0:-1] # Delete last column - not used as a feature\n",
        "    feat_imp = rf.feature_importances_\n",
        "\n",
        "    feat_sig = [a for a in zip(feat_imp, features)]\n",
        "    # Sort by importance\n",
        "    feat_sig.sort(reverse=True,key = lambda x: x[0])\n",
        "\n",
        "    print(\"IMPORTANCES: \")\n",
        "    for sig, feat in feat_sig:\n",
        "        print(\"{} : {}\".format(nls_columns[feat], sig))\n",
        "\n",
        "    return rf\n",
        "\n",
        "# Train the model\n",
        "rf_model = rand_forest_fit(df_train)"
      ],
      "metadata": {
        "id": "OY3KoTOhIbXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rand_forest_predict(rf, df):\n",
        "    # Prepare the data\n",
        "    data_arr = df.to_numpy()\n",
        "    nb_cols = numpy.shape(data_arr)[1]\n",
        "\n",
        "    predict_data = data_arr[:,0:(nb_cols-2)]\n",
        "    label_data = data_arr[:,(nb_cols-1)]\n",
        "\n",
        "    prediction = rf.predict(predict_data)\n",
        "    errors = abs(prediction - label_data)\n",
        "\n",
        "    print('Mean Absolute Error:', round(numpy.mean(errors), 4), 'degrees.')\n",
        "\n",
        "    # Plot a selection of features\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    axs[0].plot(prediction)\n",
        "    axs[1].plot(label_data)\n",
        "    plt.show()\n",
        "\n",
        "# Now predict\n",
        "rand_forest_predict(rf_model, df_pred)"
      ],
      "metadata": {
        "id": "WU8fMdwRJ1IK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}